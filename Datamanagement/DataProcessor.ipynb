{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b9d0d7",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0da4d8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: owlready2 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (0.38)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: EMMOntoPy in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: packaging>=21.0<22 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (21.3)\n",
      "Requirement already satisfied: blessings<2,>=1.7 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (1.7)\n",
      "Requirement already satisfied: numpy<2,>=1.19.5 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (1.22.3)\n",
      "Requirement already satisfied: semver<3,>=2.8.1 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (2.13.0)\n",
      "Requirement already satisfied: openpyxl<3.1,>=3.0.9 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (3.0.10)\n",
      "Requirement already satisfied: PyYAML<7,>=5.4.1 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (6.0)\n",
      "Requirement already satisfied: defusedxml<1,>=0.7.1 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (0.7.1)\n",
      "Requirement already satisfied: pyparsing>=2.4.7 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (3.0.4)\n",
      "Requirement already satisfied: Pygments<3,>=2.7.4 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (2.11.2)\n",
      "Requirement already satisfied: graphviz<0.21,>=0.16 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (0.20.1)\n",
      "Requirement already satisfied: Owlready2!=0.32,!=0.34,<0.39,>=0.28 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (0.38)\n",
      "Requirement already satisfied: Cython<0.30,>=0.29.21 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (0.29.32)\n",
      "Requirement already satisfied: pandas<1.6,>=1.2 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (1.4.3)\n",
      "Requirement already satisfied: rdflib<7,>=4.2.1 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from EMMOntoPy) (6.1.1)\n",
      "Requirement already satisfied: six in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from blessings<2,>=1.7->EMMOntoPy) (1.16.0)\n",
      "Requirement already satisfied: et-xmlfile in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from openpyxl<3.1,>=3.0.9->EMMOntoPy) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from pandas<1.6,>=1.2->EMMOntoPy) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from pandas<1.6,>=1.2->EMMOntoPy) (2022.1)\n",
      "Requirement already satisfied: setuptools in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from rdflib<7,>=4.2.1->EMMOntoPy) (61.2.0)\n",
      "Requirement already satisfied: isodate in /home/hendrik/anaconda3/envs/scrap/lib/python3.9/site-packages (from rdflib<7,>=4.2.1->EMMOntoPy) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ontology\n",
    "!pip install owlready2 \n",
    "#import owlready2 as owl\n",
    "from owlready2 import *\n",
    "import re  # To separate words based on capital letters in onto classes & to split search queries\n",
    "!pip install EMMOntoPy #Special EMMO package\n",
    "# from ontopy import get_ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a893d58d",
   "metadata": {},
   "source": [
    "## Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42667cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your imported ontology with 33 classes is ready to use\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Import Ontology & Select classes\"\"\"\n",
    "\n",
    "# write the location to the ontology to the onto_path list\n",
    "onto_path = [\"https://raw.githubusercontent.com/hendelhendel/FAIR_Battery/main/Ontology/test.owl\"]\n",
    "    # Note that all the ontology files has to be owl files.\n",
    "    \n",
    "# Import ontology\n",
    "try:\n",
    "    onto = get_ontology(onto_path[0]).load()\n",
    "except:\n",
    "    pass \n",
    "\n",
    "onto = get_ontology(onto_path[0]).load()\n",
    "\n",
    "# Collecting classes from ontology in a list\n",
    "class_raw = list(get_ontology(onto_path[0]).load().classes())\n",
    "\n",
    "# select classes by Prefix, suffix, nametags\n",
    "tag = 'ElectrochemicalFlowCell'\n",
    "prefix = 'electrochemistry.'\n",
    "\n",
    "ClassCleaner = lambda x : re.sub('_',  ' ',\\\n",
    "                                 re.sub(r\"(?<=\\w)([A-Z])\", r\" \\1\", \\\n",
    "                                 str(x).removesuffix(tag).removeprefix(prefix))) \\\n",
    "                                    if (str(x).find(prefix) != -1) else x \n",
    "                            \n",
    "\n",
    "class_select = list(map(ClassCleaner, filter(lambda x : (str(x).find(tag) != -1), class_raw)))\n",
    "\n",
    "print(\"Your imported ontology with \"  + str(len(class_select)) + \" classes is ready to use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d580e0",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de409c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your imported data is complemented with 33 ontology classes \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Import Zotero Data Base from Github and process data\"\"\"\n",
    "\n",
    "# Import raw data from github repository as dataframe\n",
    "data_path = 'https://raw.githubusercontent.com/hendelhendel/FAIR_Battery/main/Datamanagement/FlowBattKnowledgebase_1.csv'\n",
    "df_raw = pd.read_csv(data_path)\n",
    "\n",
    "            \n",
    "# To do: Make this for loop with lambda's\n",
    "def add_classes(dataframe, classes):\n",
    "    for j in classes: \n",
    "        dataframe[str(j)] = [None] * len(df_raw)\n",
    "\n",
    "add_classes(df_raw, class_select)\n",
    "print(\"Your imported data is complemented with \"  + str(len(class_select)) + \" ontology classes \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Search Abstracts data \"\"\"\n",
    "........ TODO\n",
    "\n",
    "onto_scan = lambda x: '' if () else "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb8d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Search Abstracts data \"\"\"\n",
    "# Has to be a appart file and function\n",
    "# TO DO: Read out whole files?\n",
    "# To DO: Whole files need to be in the csv files as tekst? \n",
    "\n",
    "\n",
    "\n",
    "# Read out Abstracts\n",
    "for row in range(0, len(df_flowbatt_select1)): # starts at row = 0 ends at row = leng\n",
    "    \n",
    "    # Select Abstract text\n",
    "    abstr_test = df_flowbatt_select1['Abstract Note'].iloc[row]\n",
    "    \n",
    "    # Search Abstract if esixt\n",
    "    if type(abstr_test) == str:\n",
    "        abstr_test = abstr_test.lower() # lower all capital letters\n",
    "        abstr_test_sentence = re.split(\"\\. |\\! |\\? \",abstr_test) # Split abstract per sentences in a list\n",
    "        #Scan text for ontology terms\n",
    "        for j in class_list_select:\n",
    "            \n",
    "#            df_flowbatt_select1[j].iloc[row] = [] # list to store search results [yes/no , sentence/None]\n",
    "            string = str(j).lower()  # write class as a string withoud capital letters to search text\n",
    "            if abstr_test.find(string) != -1:\n",
    "                temp_list = []\n",
    "                temp_list.append('yes')\n",
    "#                df_flowbatt_select1[j].iloc[row][0] = 'yes' # if ontoclass is found in abstract store yes\n",
    "                for sentence in abstr_test_sentence:\n",
    "                    if sentence.find(string) != -1:\n",
    "                        temp_list.append(sentence)\n",
    "                df_flowbatt_select1[j].iloc[row] = temp_list\n",
    "#                        df_flowbatt_select1[j].iloc[row][1] = sentence # * len(df_flowbatt_select1) # write answer to the right location in the dataframe\n",
    "                \n",
    "            else:\n",
    "                df_flowbatt_select1[j].iloc[row] = ['no', 'no']\n",
    "                #print(string + \": \" + str(abstr_test.find(string)) + \" found in row \" + str(row))\n",
    "                \n",
    "   # else:\n",
    "   #     print(\"Abstract is not available for \" + str(df_flowbatt_select1[\"Title\"].iloc[row]) + \" with row number \" + str(row))\n",
    "\n",
    "    \n",
    "#df_flowbatt_select1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52089ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
